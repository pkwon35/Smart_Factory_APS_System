# -*- coding: utf-8 -*-
"""Regression_최종.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xqFSx8msqoyQoaTST-7TUxlDK59g5tEh

# Regression
- TimeSeriesSplit 아닌 일반 교차검증 사용  
- train 2년, cv 3 / test 3개월
"""

from google.colab import drive
drive.mount('/content/drive')

"""### 데이터셋 - DB 수주분석테이블에 맞춰서 변수명 변경하고 전처리"""

!pip3 install pickle5
!pip install --upgrade pandas
!pip uninstall openpyxl
!pip install openpyxl

import pickle5 as pickle
with open('/content/drive/MyDrive/5조_스마트팩토리/mariadb_tables_pkl/수주분석테이블.pkl', "rb") as fh:
  수주분석테이블 = pickle.load(fh)

data = pd.read_csv('/content/drive/MyDrive/5조_스마트팩토리/진유훈/증식데이터1806_2104.csv')
data.rename(columns={'일자':'납기일자','prod_name':'제품명','prediction':'예측중량','sold_quant':'판매수량'},inplace=True)
data.drop(data.columns[0],axis=1,inplace=True)
data['납기일자'] = pd.to_datetime(data['납기일자'])

# 제품별, 일별로 합계
data = pd.pivot_table(data,
                      index=['납기일자','제품명'],
                      values=['판매수량','예측중량'],
                      aggfunc='sum')


# sold_quant 0인 값 제거
data = data[data['판매수량']!=0]

# # prediction 마이너스 값 0으로 대체
minus_idx = data[data['예측중량']<0].index.tolist()
data.loc[minus_idx,'예측중량'] = 0

data.reset_index(inplace=True)
data

with open('/content/drive/MyDrive/5조_스마트팩토리/mariadb_tables_pkl/건축착공면적.pkl', "rb") as fh:
  건축착공면적 = pickle.load(fh)
건축착공면적['TIME'] = pd.to_datetime(건축착공면적['TIME'],format='%Y%m')
건축착공면적.set_index('TIME',inplace=True)
end_date = data['납기일자']
start_date = data['납기일자']-relativedelta(years=2)

def year(x):
    date = str(x)
    year = date[:4]
    month = date[5:7]
    return int(year)

def month_(x):
    date = str(x)
    year = date[:4]
    month = date[5:7]
    return month

data['year'] = data['납기일자'].apply(year)
data['month'] = data['납기일자'].apply(month_)

건축착공면적.reset_index(inplace=True)
건축착공면적['month'] = 건축착공면적['TIME'].apply(month_)
건축착공면적.set_index('TIME',inplace=True)
건축착공면적
def need_stru(x):
    year = int(str(x)[:4])
    month = str(x)[5:7]
    need_df = 건축착공면적[f'{year-2}':f'{year-1}']
    month_need = need_df[need_df['month']==month]['건축착공면적'].mean()
    return month_need

data['착공지수'] = data['납기일자'].apply(need_stru)

result_data = data[['납기일자','제품명','예측중량','판매수량','착공지수']]
result_data

############### 예측할때만 이거 쓰기 ###################
with open('/content/drive/MyDrive/5조_스마트팩토리/mariadb_tables_pkl/건축착공면적.pkl', "rb") as fh:
  건축착공면적 = pickle.load(fh)
건축착공면적['TIME'] = pd.to_datetime(건축착공면적['TIME'],format='%Y%m')
# today = datetime.today().strftime('%Y-%m-%d')
std_date = datetime.strptime('2021-04-25', '%Y-%m-%d')
start_date = std_date - relativedelta(years=2)
start_date = datetime.strftime(start_date,'%Y-%m-%d')
건축착공면적 = 건축착공면적[건축착공면적['TIME']>=start_date]
건축착공면적['month'] = 건축착공면적.TIME.dt.month
건축착공면적=pd.DataFrame(건축착공면적.groupby('month')['건축착공면적'].mean())
건축착공면적.reset_index(inplace=True)
건축착공면적

"""# 분석용 데이터셋 생성"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
import pickle5 as pickle

data = pd.read_csv('/content/drive/MyDrive/5조_스마트팩토리/진유훈/증식데이터1806_2104.csv')
data.rename(columns={'일자':'납기일자','prod_name':'제품명','prediction':'예측중량','sold_quant':'판매수량'},inplace=True)
data.drop(data.columns[0],axis=1,inplace=True)
data['납기일자'] = pd.to_datetime(data['납기일자'])

# 제품별, 일별로 합계
data = pd.pivot_table(data,
                      index=['납기일자','제품명'],
                      values=['판매수량','예측중량'],
                      aggfunc='sum')
data.reset_index(inplace=True)

# # sold_quant 0인 값 제거
# data = data[data['판매수량']!=0]

# # # prediction 마이너스 값 0으로 대체
# minus_idx = data[data['예측중량']<0].index.tolist()
# data.loc[minus_idx,'예측중량'] = 0

data.head()

with open('/content/drive/MyDrive/5조_스마트팩토리/mariadb_tables_pkl/건축착공면적.pkl', "rb") as fh:
  건축착공면적 = pickle.load(fh)
건축착공면적['TIME'] = pd.to_datetime(건축착공면적['TIME'],format='%Y%m')
건축착공면적.set_index('TIME',inplace=True)
건축착공면적.head()

def year(x):
    date = str(x)
    year = date[:4]
    month = date[5:7]
    return int(year)

def month_(x):
    date = str(x)
    year = date[:4]
    month = date[5:7]
    return month

data['year'] = data['납기일자'].apply(year)
data['month'] = data['납기일자'].apply(month_)

건축착공면적.reset_index(inplace=True)
건축착공면적['month'] = 건축착공면적['TIME'].apply(month_)
건축착공면적.set_index('TIME',inplace=True)
건축착공면적
def need_stru(x):
    year = int(str(x)[:4])
    month = str(x)[5:7]
    need_df = 건축착공면적[f'{year-2}':f'{year-1}']
    month_need = need_df[need_df['month']==month]['건축착공면적'].mean()
    return month_need

data['착공지수'] = data['납기일자'].apply(need_stru)
data.head()
# result_data = data[['납기일자','제품명','예측중량','판매수량','착공지수']]
# result_data

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
import pickle5 as pickle
from sklearn.preprocessing import MinMaxScaler
data = pd.read_csv('/content/drive/MyDrive/5조_스마트팩토리/진유훈/증식데이터1806_2104.csv')
data.rename(columns={'일자':'납기일자','prod_name':'제품명','prediction':'예측중량','sold_quant':'판매수량'},inplace=True)
data.drop(data.columns[0],axis=1,inplace=True)
data['납기일자'] = pd.to_datetime(data['납기일자'])

# 제품별, 일별로 합계
data = pd.pivot_table(data,
                      index=['납기일자','제품명'],
                      values=['판매수량','예측중량'],
                      aggfunc='sum')


# sold_quant 0인 값 제거
data = data[data['판매수량']!=0]

# # prediction 마이너스 값 0으로 대체
minus_idx = data[data['예측중량']<0].index.tolist()
data.loc[minus_idx,'예측중량'] = 0
data.reset_index(inplace=True)

# 건축착공면적 불러와서 전처리

with open('/content/drive/MyDrive/5조_스마트팩토리/mariadb_tables_pkl/건축착공면적.pkl', "rb") as fh:
  건축착공면적 = pickle.load(fh)
건축착공면적['TIME'] = pd.to_datetime(건축착공면적['TIME'],format='%Y%m')
건축착공면적.set_index('TIME',inplace=True)



def year(x):
    date = str(x)
    year = date[:4]
    month = date[5:7]
    return int(year)

def month_(x):
    date = str(x)
    year = date[:4]
    month = date[5:7]
    return month

data['year'] = data['납기일자'].apply(year)
data['month'] = data['납기일자'].apply(month_)

건축착공면적.reset_index(inplace=True)
건축착공면적['month'] = 건축착공면적['TIME'].apply(month_)
건축착공면적.set_index('TIME',inplace=True)
건축착공면적
def need_stru(x):
    year = int(str(x)[:4])
    month = str(x)[5:7]
    need_df = 건축착공면적[f'{year-2}':f'{year-1}']
    month_need = need_df[need_df['month']==month]['건축착공면적'].mean()
    return month_need

data['착공지수'] = data['납기일자'].apply(need_stru)

data = data[['납기일자','제품명','예측중량','판매수량','착공지수']]
data.set_index('납기일자',inplace=True)



# # sold_quant, prediction 로그변환
scaler = MinMaxScaler()
data[['착공지수']] = scaler.fit_transform(data[['착공지수']])
data[['판매수량','예측중량']] = np.log1p(data[['판매수량','예측중량']])

# # month, year drop
# data.drop(['month','year'],axis=1,inplace=True)

# # prod_name 원핫인코딩
data = pd.get_dummies(data)

data.head()

"""# 추가 독립변수
- 월평균 기온(상관계수 낮아서 삭제)
- 월평균 강수량(상관계수 낮아서 삭제)
"""

# # 월평균 기온, 월평균 강수량 컬럼 추가

# def weather(data):
#   data = data.reset_index()
#   weather = pd.read_pickle('/content/drive/MyDrive/5조_스마트팩토리/진유훈/temp18_21.pkl')
#   weather.drop(['시도','신적설량'],axis=1,inplace=True)
#   weather['일자'] = pd.to_datetime(weather['일자'])

#   grouped_ta = weather.groupby(weather.일자.dt.month)['기온'].mean()
#   grouped_rn = weather.groupby(weather.일자.dt.month)['강수량'].mean()

#   # 월평균 기온
#   def m_temp(month):
#       if month in [1]: return grouped_ta.iloc[0]
#       elif month in [2]: return grouped_ta.iloc[1]   
#       elif month in [3]: return grouped_ta.iloc[2]
#       elif month in [4]: return grouped_ta.iloc[3]
#       elif month in [5]: return grouped_ta.iloc[4]
#       elif month in [6]: return grouped_ta.iloc[5]
#       elif month in [7]: return grouped_ta.iloc[6]
#       elif month in [8]: return grouped_ta.iloc[7]
#       elif month in [9]: return grouped_ta.iloc[8]
#       elif month in [10]: return grouped_ta.iloc[9]
#       elif month in [11]: return grouped_ta.iloc[10]
#       elif month in [12]: return grouped_ta.iloc[11]

#   # 월평균 강수량
#   def m_rain(month):
#       if month in [1]: return grouped_rn.iloc[0]
#       elif month in [2]: return grouped_rn.iloc[1]   
#       elif month in [3]: return grouped_rn.iloc[2]
#       elif month in [4]: return grouped_rn.iloc[3]
#       elif month in [5]: return grouped_rn.iloc[4]
#       elif month in [6]: return grouped_rn.iloc[5]
#       elif month in [7]: return grouped_rn.iloc[6]
#       elif month in [8]: return grouped_rn.iloc[7]
#       elif month in [9]: return grouped_rn.iloc[8]
#       elif month in [10]: return grouped_rn.iloc[9]
#       elif month in [11]: return grouped_rn.iloc[10]
#       elif month in [12]: return grouped_rn.iloc[11]

#   data['m_temp'] = data['납기일자'].dt.month.apply(m_temp)
#   data['m_rain'] = data['납기일자'].dt.month.apply(m_rain)
#   data = data.set_index('납기일자')
#   return data

# data = weather(data)

"""# 최적 모델 및 하이퍼 파라미터 탐색"""

def Regression(data):
  from datetime import datetime
  from dateutil.relativedelta import relativedelta
  from sklearn.metrics import mean_squared_error , r2_score
  from sklearn.linear_model import Ridge, Lasso
  from sklearn.tree import DecisionTreeRegressor
  from sklearn.ensemble import RandomForestRegressor
  from xgboost import XGBRegressor
  from lightgbm import LGBMRegressor
  from sklearn.model_selection import GridSearchCV
  import joblib

  # 종속변수, 독립변수 분할
  y = data['판매수량']
  X = data.drop('판매수량',axis=1)

  # train, validation, test 분할
  test_end = data.index.max()
  test_start = test_end - relativedelta(months=3)
  train_end = test_start - relativedelta(days=1)
  train_start = test_end - relativedelta(years=2)
  
  X_test = X[test_start:test_end]
  y_test = y[test_start:test_end]
  X_train = X[train_start:train_end]
  y_train = y[train_start:train_end]

# 객체 생성
  ridge = Ridge(random_state=1004)
  lasso = Lasso(random_state=1004)
  dt_reg = DecisionTreeRegressor(random_state=1004)
  rf_reg = RandomForestRegressor(random_state=1004)
  xgb_reg = XGBRegressor(objective='reg:squarederror',random_state=1004)
  lgbm_reg = LGBMRegressor(random_state=1004)

  # 파라미터 설정
  ridge_parameters = {'alpha':[0.1,0.5,1.0]} # 0.5
  lasso_parameters = {'alpha':[0.0001,0.0003,0.0005]}
  dt_parameters = {'max_depth':[3,5,7]}
  rf_parameters = {'n_estimators':[300, 400, 500, 600, 700, 800, 900, 1000],
                   'min_samples_split':[25,50,75,100]}
  xgb_parameters = {'n_estimators':[100, 200,300,400],
                    'learning_rate':[0.01,0.05,0.1],
                    'max_depth':[2,4,6,8]}
  lgbm_parameters = {'n_estimators':[100,300,500,700,800,1000],
                    'learning_rate':[0.01, 0.05,0.1,0.5],
                    'colsample_bytree':[0.5,0.75,1.0]}

  reg_param = [(ridge,ridge_parameters),
               (lasso,lasso_parameters),
               (dt_reg,dt_parameters),
               (rf_reg,rf_parameters),
               (xgb_reg,xgb_parameters),
               (lgbm_reg,lgbm_parameters)]

  for reg, parameter in reg_param:
    grid_reg = GridSearchCV(reg, param_grid=parameter,
                            scoring='neg_mean_squared_error',
                            cv=3)
    
    grid_reg.fit(X_train, y_train)

    # 교차검증 결과 출력
    class_name = reg.__class__.__name__
    print(f'<<<<< {class_name} >>>>>')
    scores_df = pd.DataFrame(grid_reg.cv_results_)
    display(scores_df[['params','rank_test_score','mean_test_score']])
    print(f'{class_name} 최적 하이퍼 파라미터:',grid_reg.best_params_)
    print('{0} 최고 MSLE:{1:.4f}'.format(class_name,-1 * grid_reg.best_score_))
    print('{0} 최고 RMSLE:{1:.4f}'.format(class_name,np.sqrt(-1 * grid_reg.best_score_)))

    
    # test data에 최적 하이퍼 파라미터 적용하여 분석한 결과
    best_reg = grid_reg.best_estimator_
    pred = best_reg.predict(X_test)

    y_pred_expm = np.expm1(pred)
    y_test_expm = np.expm1(y_test)

    msle = mean_squared_error(y_test, pred)
    rmsle = np.sqrt(msle)
    accuracy = r2_score(y_test_expm, y_pred_expm)

    print('MLSE scores:{0:.4f}'.format(msle))
    print('RMLSE scores:{0:.4f}'.format(rmsle))
    print('테스트 데이터 세트 정확도:{:.4f}'.format(accuracy))
    print('='*80)
    print()

Regression(data)

"""# 최적 모델 저장"""

from datetime import datetime
from dateutil.relativedelta import relativedelta
from sklearn.metrics import mean_squared_error , r2_score
from sklearn.linear_model import Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.model_selection import GridSearchCV
import joblib

# 종속변수, 독립변수 분할
y = data['판매수량']
X = data.drop('판매수량',axis=1)

# train, validation, test 분할
test_end = data.index.max()
test_start = test_end - relativedelta(months=3)
train_end = test_start - relativedelta(days=1)
train_start = test_end - relativedelta(years=2)

X_test = X[test_start:test_end]
y_test = y[test_start:test_end]
X_train = X[train_start:train_end]
y_train = y[train_start:train_end]


# RandomForestRegressor & LGBM 혼합모델
rf_reg = RandomForestRegressor(random_state=1004)
rf_parameters = {'n_estimators':[50,100,300,500,1000],
                  'min_samples_split':[25,50,75,100]}
grid_rf = GridSearchCV(rf_reg, param_grid=rf_parameters,
                       scoring='neg_mean_squared_error',cv=3)
grid_rf.fit(X_train, y_train)
pred_rf = grid_rf.predict(X_test)


lgbm_reg = LGBMRegressor(random_state=1004)
lgbm_parameters = {'n_estimators':[100,300,500,700,800,1000],
                  'learning_rate':[0.01, 0.05,0.1,0.5],
                  'colsample_bytree':[0.5,0.75,1.0]}
grid_lgbm = GridSearchCV(lgbm_reg, param_grid=lgbm_parameters,
                       scoring='neg_mean_squared_error',cv=3)
grid_lgbm.fit(X_train, y_train)
pred_lgbm = grid_lgbm.predict(X_test)                  

# xgb_reg = XGBRegressor(objective='reg:squarederror',random_state=1004)
# xgb_parameters = {'n_estimators':[200,300,400],
#                     'learning_rate':[0.01,0.05,0.1],
#                     'max_depth':[2,4,6,8]}
# grid_xgb = GridSearchCV(xgb_reg, param_grid=xgb_parameters,
#                        scoring='neg_mean_squared_error',cv=3)
# grid_xgb.fit(X_train, y_train)
# pred_xgb = grid_xgb.predict(X_test)


pred = 0.5 * pred_rf + 0.5 * pred_lgbm

pred_expm = np.expm1(pred)
y_test_expm = np.expm1(y_test)

msle = mean_squared_error(y_test, pred)
rmsle = np.sqrt(msle)
accuracy = r2_score(y_test_expm, pred_expm)

print('RF & XGB 혼합모델 MLSE scores:{0:.4f}'.format(msle))
print('RF & XGB 혼합모델 RMLSE scores:{0:.4f}'.format(rmsle))
print('테스트 데이터 세트 정확도:{:.4f}'.format(accuracy))
print('='*80)
print()

"""# 모델 저장"""

from sklearn.externals import joblib
joblib.dump(grid_rf, "/content/drive/MyDrive/5조_스마트팩토리/권준기/배송이_예측모델/회귀모델_save_final/grid_rf.joblib.dat")
# joblib.dump(grid_lgbm, "/content/drive/MyDrive/5조_스마트팩토리/권준기/배송이_예측모델/회귀모델_save_final/grid_lgbm.joblib.dat")

"""# 모델 저장(방법2)
  
코드 참고 : https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/  
** joblib 사용 시 DB에서 에러남/해결됨
"""

# import pickle

# filename1 = '/content/drive/MyDrive/5조_스마트팩토리/조현정/Regression_models/rf_reg.sav'
# pickle.dump(grid_rf, open(filename1, 'wb'))

# filename2 = '/content/drive/MyDrive/5조_스마트팩토리/조현정/Regression_models/lgbm_reg.sav'
# pickle.dump(grid_lgbm, open(filename2, 'wb'))


# # 모델 사용 예시
# loaded_model = pickle.load(open(filename, 'rb'))
# result = loaded_model.score(X_test, y_test)
# print(result)

"""## DB에서 중장기수주예측 불러와서 단기생판량 예측할 때"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import pickle5 as pickle
from dateutil.relativedelta import relativedelta
from datetime import datetime, timedelta





with open('/content/drive/MyDrive/5조_스마트팩토리/mariadb_tables_pkl/중장기수주예측.pkl', "rb") as fh:
  중장기수주예측 = pickle.load(fh)

std_date = std_date = datetime.strptime("2021-04-25", "%Y-%m-%d")
end_date = std_date + relativedelta(days=95)
중장기수주예측 = 중장기수주예측[(중장기수주예측['납기일자']>=std_date) & (중장기수주예측['납기일자']<=end_date)]

df = 중장기수주예측.copy()
df.set_index('납기일자',inplace=True)
df['예측중량'] = np.log1p(df['예측중량'])
df.fillna(0,inplace=True)

with open('/content/drive/MyDrive/5조_스마트팩토리/mariadb_tables_pkl/건축착공면적.pkl', "rb") as fh:
  건축착공면적 = pickle.load(fh)
건축착공면적['TIME'] = pd.to_datetime(건축착공면적['TIME'],format='%Y%m')
# today = datetime.today().strftime('%Y-%m-%d')
std_date = datetime.strptime('2021-04-25', '%Y-%m-%d')
start_date = std_date - relativedelta(years=2)

def cat(df):
  df = df[df['TIME']>=start_date]
  df['month'] = df.TIME.dt.month
  df = pd.DataFrame(df.groupby('month')['건축착공면적'].mean())
  df.reset_index(inplace=True)
  return df

건축착공면적 = cat(건축착공면적)

df.reset_index(inplace=True)
df['month'] = df['납기일자'].dt.month
# data['year'] = data['납기일자'].dt.year
df = pd.merge(df, 건축착공면적, on='month', how='left')
df.set_index('납기일자',inplace=True)


df = pd.get_dummies(df)

df.reset_index(inplace=True)

X_test = df.drop(['납기일자','month'], axis =1)



#############################
grid_rf = joblib.load('/content/drive/MyDrive/5조_스마트팩토리/권준기/배송이_예측모델/회귀모델_save_final/grid_rf.joblib.dat')
#############################


# #############################
# grid_xgb = joblib.load('/content/drive/MyDrive/5조_스마트팩토리/권준기/배송이_예측모델/회귀모델_save/grid_xgb.joblib.dat')
#############################


pred_rf = grid_rf.predict(X_test)
# pred_xgb = grid_xgb.predict(X_test)
# pred_혼합 = 0.5 * pred_rf + 0.5 * pred_xgb


pred = pd.DataFrame(pred_rf,columns=['생산량'])
pred['생산량'] = np.ceil(np.expm1(pred.생산량))
중장기수주예측 = 중장기수주예측[['납기일자','제품명']]
중장기수주예측.reset_index(drop=True,inplace=True)
생판계획 = pd.concat([중장기수주예측,pred],axis=1)

pd.set_option('display.max_rows',None)
생판계획.sort_values(by='납기일자',ascending=True,inplace=True)
생판계획.reset_index(drop=True,inplace=True)
생판계획

X_test